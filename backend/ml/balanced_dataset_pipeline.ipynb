{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78198bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare classes detected. Removing problematic classes...\n",
      "Data resampling with SMOTEENN complete!\n",
      "Original training dataset size: 152\n",
      "Resampled training dataset size: 260\n",
      "Number of unique classes after resampling: 52\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1: Load and preprocess dataset\n",
    "df = pd.read_csv(\"../data/recipes.csv\")\n",
    "\n",
    "# Clean text data (example cleaning function)\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    return text\n",
    "\n",
    "df['cleaned_ingredients'] = df['ingredients'].apply(clean_text)\n",
    "\n",
    "# Vectorize the ingredients\n",
    "vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['cleaned_ingredients'])\n",
    "y = df['recipe_name']\n",
    "\n",
    "# Step 2: Filter out classes with fewer than 2 samples\n",
    "min_samples = 2  # Minimum samples required in a class\n",
    "class_counts = pd.Series(y).value_counts()\n",
    "valid_classes = class_counts[class_counts >= min_samples].index\n",
    "mask = y.isin(valid_classes)\n",
    "\n",
    "# Apply the mask to X and y\n",
    "y = y[mask]\n",
    "X = X[mask.to_numpy()]  # Convert mask to numpy for sparse matrix compatibility\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Resampling with error handling\n",
    "def resample_with_error_handling(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Resample the dataset using SMOTEENN with custom configurations. If errors are encountered,\n",
    "    problematic classes will be dynamically removed.\n",
    "    \"\"\"\n",
    "    smote = SMOTE(k_neighbors=1, random_state=42)  # Use k_neighbors=1 to handle minority classes\n",
    "    enn = EditedNearestNeighbours(n_neighbors=1)  # Use n_neighbors=1 for the ENN step\n",
    "    smote_enn = SMOTEENN(smote=smote, enn=enn, random_state=42)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Attempt to resample\n",
    "            X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "            return X_resampled, y_resampled\n",
    "        except ValueError as e:\n",
    "            # Handle the ValueError caused by rare classes\n",
    "            if \"Expected n_neighbors <= n_samples_fit\" in str(e):\n",
    "                print(\"Rare classes detected. Removing problematic classes...\")\n",
    "                # Identify and remove classes with fewer than 2 samples\n",
    "                class_counts = pd.Series(y_train).value_counts()\n",
    "                valid_classes = class_counts[class_counts >= 2].index\n",
    "                mask = y_train.isin(valid_classes)\n",
    "\n",
    "                # Update X_train and y_train\n",
    "                y_train = y_train[mask]\n",
    "                X_train = X_train[mask.to_numpy()]\n",
    "            else:\n",
    "                # Raise other unexpected errors\n",
    "                raise e\n",
    "\n",
    "# Apply resampling with error handling\n",
    "X_resampled, y_resampled = resample_with_error_handling(X_train, y_train)\n",
    "\n",
    "# Step 4: Print summary of resampling\n",
    "print(\"Data resampling with SMOTEENN complete!\")\n",
    "print(f\"Original training dataset size: {len(y_train)}\")\n",
    "print(f\"Resampled training dataset size: {len(y_resampled)}\")\n",
    "print(f\"Number of unique classes after resampling: {len(pd.Series(y_resampled).value_counts())}\")\n",
    "\n",
    "# Continue with the rest of your model training pipeline..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
